{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RUN THESE FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = [x for x in range(2018,2016,-1)]\n",
    "court_list = ['frontcourt','backcourt']\n",
    "conference_list = ['eastern','western',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# https://www.basketball-reference.com/allstar/NBA_2017_voting-frontcourt-eastern-conference.html\n",
    "concat_list = []\n",
    "for year in year_list:\n",
    "    for court in court_list:\n",
    "        for conference in conference_list:\n",
    "            url = 'https://www.basketball-reference.com/allstar/NBA_{sub1}_voting-{sub2}-{sub3}-conference.html'\n",
    "            response = requests.get(url.format(sub1 =year, sub2 =court,sub3 =conference))\n",
    "            page = response.text\n",
    "            soup = BeautifulSoup(page, \"lxml\")\n",
    "            text_all=''\n",
    "            # scrapes html from website with player name and votes\n",
    "            all = soup.find_all(\n",
    "                   lambda tag: tag.name == 'td' and (tag['data-stat'] == 'player_name' or tag['data-stat'] == 'fan_votes')\n",
    "               )\n",
    "\n",
    "            #takes text portion of html and cleans data using RegEx\n",
    "            for i in range(len(all)):\n",
    "                text_all += all[i].text\n",
    "                string = re.sub(r'([a-zA-Z])(\\d)', r'\\1,\\2',text_all)\n",
    "                string = re.sub(r'(\\d)([a-zA-Z])', r'\\1,\\2',string)\n",
    "                string = re.sub(r'(\\d),(\\d)', r'\\1\\2', string)\n",
    "                string = re.sub(r'([a-zA-Z]\\.)(\\d)', r'\\1,\\2',string)\n",
    "\n",
    "            # creates list with player names and votes as separate elements\n",
    "            all_list = string.split(\",\")\n",
    "\n",
    "            # creates a list of list, combining player name and votes into one list, and inserting year as well\n",
    "            new_list = []\n",
    "            it = iter(all_list)\n",
    "            for x in it:\n",
    "                new_list.append([x, int(next(it))])\n",
    "            for player_vote in new_list:\n",
    "                player_vote.insert(0,year)\n",
    "            df = pd.DataFrame(new_list, columns=['Year', 'Player','Votes'])\n",
    "            concat_list.append(df)\n",
    "            \n",
    "df_recent = pd.concat(concat_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# filename = '2018_votes_pickle'\n",
    "# outfile = open(filename,'wb')\n",
    "# pickle.dump(df_recent,outfile)\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '2018_votes_pickle'\n",
    "infile = open(filename,'rb')\n",
    "df_recent = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "lists_of_stats = []\n",
    "\n",
    "for year in year_list:\n",
    "    for court in court_list:\n",
    "        for conference in conference_list:\n",
    "            url = 'https://www.basketball-reference.com/allstar/NBA_{sub1}_voting-{sub2}-{sub3}-conference.html'\n",
    "            response = requests.get(url.format(sub1 =year, sub2 =court,sub3 =conference))\n",
    "            page = response.text\n",
    "            soup = BeautifulSoup(page, \"lxml\")\n",
    "            all = soup.find_all(\n",
    "                       lambda tag: tag.name == 'td' and (tag['data-stat'] == 'player_name' or tag['data-stat'] == 'fan_votes'))\n",
    "            index_all = [x for x in range(0,len(all),2)]\n",
    "            list_links = []\n",
    "            for i in index_all:\n",
    "                all = soup.find_all(\n",
    "                       lambda tag: tag.name == 'td' and (tag['data-stat'] == 'player_name' or tag['data-stat'] == 'fan_votes')\n",
    "                   )[i].find('a')['href']\n",
    "                list_links.append(all)\n",
    "\n",
    "            for stats_link in list_links:\n",
    "                url_stats_new = 'https://www.basketball-reference.com{}'\n",
    "                response_stats_new = requests.get(url_stats_new.format(stats_link))\n",
    "                page_stats_new = response_stats_new.text\n",
    "                soup_stats_new = BeautifulSoup(page_stats_new, \"lxml\")\n",
    "                pergame = soup_stats_new.find('tr', id =('per_game.'+ str(year)))\n",
    "                pergame_diff = soup_stats_new.find('tr', id =('per_game.'+ str(year-1))) #added\n",
    "                if pergame:\n",
    "                    find_pergame = pergame.find_all(\n",
    "                        lambda tag: tag.name == 'td' and tag['data-stat'])\n",
    "                    stat_list = []\n",
    "                    for stat in range(len(find_pergame)):\n",
    "                        stat_list.append(find_pergame[stat].text)\n",
    "                    \n",
    "                    if pergame_diff: # added\n",
    "                        find_pergame_diff = pergame_diff.find_all(\n",
    "                        lambda tag: tag.name == 'td' and tag['data-stat'])\n",
    "                        stat_list.append(find_pergame_diff[-1].text)\n",
    "                    else:\n",
    "                        stat_list.append(\"None\")\n",
    "                                                             \n",
    "                    if pergame.find_all(class_ = \"sr_star\"):\n",
    "                        stat_list.append(1)\n",
    "                    else:\n",
    "                        stat_list.append(0)\n",
    "                else:\n",
    "                    stat_list = [0]*30\n",
    "            #         stat_list.insert(0,f + \" \" + l)\n",
    "                stat_list.insert(0,year)\n",
    "                lists_of_stats.append(stat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(lists_of_stats, columns=['Year', 'Age','Team','League','Pos','GP','GS', 'MP','FG','FGA','FG%','3P','3PA','3P%','2P','2PA','2P%','eFG%','FT','FTA','FT%','ORB','DRB','TRB','AST','STL','BLK','TOV','PF','PTS','Prev_PTS','Star',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# filename3 = '2018_stats_pickle'\n",
    "# outfile3 = open(filename3,'wb')\n",
    "# pickle.dump(df_stats,outfile3)\n",
    "# outfile3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename3 = '2018_stats_pickle'\n",
    "infile = open(filename3,'rb')\n",
    "df_2018_stats = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = [x for x in range(0,963)]\n",
    "df_recent_r = df_recent.reset_index()\n",
    "df_recent_r['index'] = new_index\n",
    "df_recent_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_stats_r = df_2018_stats.reset_index()\n",
    "df_2018_stats_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_2018 = df_recent_r.merge(df_2018_stats_r, how='left',on=['index','Year'])\n",
    "df_merge_2018 = df_merge_2018.drop(columns = 'index')\n",
    "df_merge_2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL COMBINE WITH 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename2 = 'df_2016'\n",
    "infile = open(filename2,'rb')\n",
    "df_2016 = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_merge_2018,df_2016],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby('Player', as_index=False).Star.sum().sort_values('Star', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_df = df_all.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_df['Cum_Star'] = reversed_df.groupby(['Player'])['Star'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = reversed_df.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "df_all.columns = ['Year', 'Player', 'Votes', 'Age', 'Team', 'League', 'Pos', 'GP', 'GS',\n",
    "       'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%',\n",
    "       'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK',\n",
    "       'TOV', 'PF', 'PTS', 'PTS_PREV', 'Star', 'Cum_Star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# filename5 = 'df_all'\n",
    "# outfile5 = open(filename5,'wb')\n",
    "# pickle.dump(df_all,outfile5)\n",
    "# outfile5.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
